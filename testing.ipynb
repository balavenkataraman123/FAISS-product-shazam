{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision.transforms as T\n",
    "from transformers import AutoFeatureExtractor, AutoModel\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"google/vit-base-patch16-224-in21k\"\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "hidden_dim = model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the image\n",
    "transformation_chain = T.Compose(\n",
    "    [\n",
    "        # resize and tensorize\n",
    "        T.Resize((224,224)),\n",
    "        T.ToTensor()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model: torch.nn.Module, images):\n",
    "    device = model.device\n",
    "\n",
    "\n",
    "    # `transformation_chain` is a compostion of preprocessing\n",
    "    # transformations we apply to the input images to prepare them\n",
    "    # for the model. For more details, check out the accompanying Colab Notebook.\n",
    "    image_batch_transformed = torch.stack(\n",
    "        [transformation_chain(image) for image in images]\n",
    "    )\n",
    "    new_batch = image_batch_transformed.to(device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(new_batch).last_hidden_state[:, 0].cpu()\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [Image.open(\"data/\" + str(k) + \".jpg\") for k in range(1,5)]\n",
    "image1 = [Image.open(\"data/doritos.png\").convert(\"RGB\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdev = model.to(\"cuda\")\n",
    "embeddings2 = extract_embeddings(mdev, images)\n",
    "embeddings1 = extract_embeddings(mdev, image1)\n",
    "embeddings = np.array([np.array(i) for i in list(embeddings2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "vector_dimension = embeddings.shape[1]\n",
    "print(vector_dimension)\n",
    "index = faiss.IndexFlatL2(vector_dimension)\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84335566 0.9449022 ]]\n",
      "[[0 2]]\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "_vector = np.array(embeddings1)\n",
    "faiss.normalize_L2(_vector)\n",
    "distances, ann = index.search(_vector, k=k)\n",
    "print(distances)\n",
    "print(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_efficient_cosine_similarity(source_representation, test_representation):\n",
    "    a = np.dot(source_representation, test_representation)\n",
    "    b = np.sqrt(source_representation.dot(source_representation))\n",
    "    c = np.sqrt(test_representation.dot(test_representation))\n",
    "    return 1 - (a / (b*c))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.4217), tensor(0.5853), tensor(0.4725), tensor(0.6342)]\n",
      "Doritos\n"
     ]
    }
   ],
   "source": [
    "categories = [\"Doritos\", \"Lays\", \"Cheetos\", \"Sun chips\"]\n",
    "\n",
    "csim = [find_efficient_cosine_similarity(i, embeddings1[0]) for i in embeddings]\n",
    "print(csim)\n",
    "print(categories[csim.index(min(csim))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
